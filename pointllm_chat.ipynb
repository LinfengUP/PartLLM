{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983f43e-5633-4030-8597-2e8685c7bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "from pointllm.conversation import conv_templates, SeparatorStyle\n",
    "from pointllm.utils import disable_torch_init\n",
    "from pointllm.model import *\n",
    "from pointllm.model.utils import KeywordsStoppingCriteria\n",
    "\n",
    "from pointllm.data import load_ulip2_objaverse_point_cloud\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e7dc95-81f6-4e23-8933-78df74bd34b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(args):\n",
    "    # Model\n",
    "    disable_torch_init()\n",
    "\n",
    "    model_path = args.model_path \n",
    "    print(f'[INFO] Model name: {model_path}')\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = PointLLMLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=False, use_cache=True, torch_dtype=torch.float16).cuda()\n",
    "                                                     # args.torch_dtype).cuda()\n",
    "    model.initialize_tokenizer_point_backbone_config_wo_embedding(tokenizer)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    mm_use_point_start_end = getattr(model.config, \"mm_use_point_start_end\", False)\n",
    "    # Add special tokens ind to model.point_config\n",
    "    point_backbone_config = model.get_model().point_backbone_config\n",
    "    \n",
    "    if mm_use_point_start_end:\n",
    "        if \"v1\" in model_path.lower():\n",
    "            conv_mode = \"vicuna_v1_1\"\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        conv = conv_templates[conv_mode].copy()\n",
    "\n",
    "    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "    keywords = [stop_str]\n",
    "    \n",
    "    return model, tokenizer, point_backbone_config, keywords, mm_use_point_start_end, conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee85d31-d7e9-43d5-9ef6-09e02569dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def pc_norm(pc):\n",
    "    \"\"\" pc: NxC, return NxC \"\"\"\n",
    "    xyz = pc[:, :3]\n",
    "    other_feature = pc[:, 3:]\n",
    "\n",
    "    centroid = np.mean(xyz, axis=0)\n",
    "    xyz = xyz - centroid\n",
    "    m = np.max(np.sqrt(np.sum(xyz ** 2, axis=1)))\n",
    "    xyz = xyz / m\n",
    "\n",
    "    pc = np.concatenate((xyz, other_feature), axis=1)\n",
    "    return pc\n",
    "def load_ulip2_objaverse_point_cloud(data_path, object_id, pointnum=8192, use_color=False):\n",
    "\n",
    "    if not use_color:\n",
    "        filename = f\"{object_id}/{object_id}_{pointnum}.npz\"\n",
    "        point_cloud = np.load(os.path.join(data_path, filename))['arr_0'] # * pointnum, 3 array\n",
    "    else:\n",
    "        filename = f\"{object_id}_{pointnum}.npy\"\n",
    "        point_cloud = np.load(os.path.join(data_path, filename))\n",
    "\n",
    "    # * normalize\n",
    "    point_cloud = pc_norm(point_cloud)\n",
    "\n",
    "    return point_cloud\n",
    "\n",
    "def load_my_own_point_cloud(object_id):\n",
    "    # /data2/llf/fss_data/ScanNet/scenes/data/scene0000_00.npy\n",
    "    point_cloud = np.load(object_id)\n",
    "    point_cloud = point_cloud[:,:6]\n",
    "    point_cloud[:,3:] = point_cloud[:,3:]/255\n",
    "\n",
    "    point_cloud = pc_norm(point_cloud)\n",
    "\n",
    "    return torch.from_numpy(point_cloud).unsqueeze_(0).to(torch.float32)\n",
    "    \n",
    "\n",
    "def load_point_cloud(args):\n",
    "    object_id = args.object_id\n",
    "    print(f\"[INFO] Loading point clouds using object_id: {object_id}\")\n",
    "    point_cloud = load_ulip2_objaverse_point_cloud(args.data_path, object_id, pointnum=8192, use_color=True)\n",
    "    \n",
    "    return object_id, torch.from_numpy(point_cloud).unsqueeze_(0).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1100e74-3998-4c26-9cee-bf17fa2fa532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model-path\", type=str, \\\n",
    "default=\"RunsenXu/PointLLM_7B_v1.1\")\n",
    "\n",
    "parser.add_argument(\"--data-path\", type=str, default=\"/data2/llf/objaverse/8192_npy\")\n",
    "parser.add_argument(\"--torch-dtype\", type=str, default=\"float32\", choices=[\"float32\", \"float16\", \"bfloat16\"])\n",
    "args = parser.parse_args(args=[])\n",
    "    # '--torch-dtype','float32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4574b18-a8d2-4086-a941-ff1febc535bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model name: RunsenXu/PointLLM_7B_v1.1\n",
      "Loading PointBERT config from /home/linfeng/PartLLM/pointllm/model/pointbert/PointTransformer_base_8192point.yaml.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea0e4ab09fd433d8307a483560b90e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer, point_backbone_config, keywords, mm_use_point_start_end, conv = init_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38732631-d5cf-47fd-965b-1dd6dca07b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_token_len = point_backbone_config['point_token_len']\n",
    "default_point_patch_token = point_backbone_config['default_point_patch_token']\n",
    "default_point_start_token = point_backbone_config['default_point_start_token']\n",
    "default_point_end_token = point_backbone_config['default_point_end_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e9f98ee-ec95-48fd-af8f-484e362c1df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "[INFO] Please enter the object_id or 'q' to quit:  /data2/llf/fss_data/ScanNet/scenes/data/scene0011_00.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Chatting with object_id: /data2/llf/fss_data/ScanNet/scenes/data/scene0011_00.npy.\n",
      "[INFO] Loading point clouds using object_id: /data2/llf/fss_data/ScanNet/scenes/data/scene0011_00.npy\n",
      "torch.Size([1, 206883, 6])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "USER:  what is this\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT: The 3D model represents a meticulously designed house that is colored in different shades of grey. It consists of several rooms, possibly indicating several functionalities such as bedrooms, living rooms, kitchen etc. The grey color gives it a classic yet modern look. Houses such as these are generally associated with residential purposes and are usually seen in suburban areas.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Start a loop for multiple rounds of dialogue\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# This if-else block ensures the initial question from the user is included in the conversation\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     qs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m qs \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pointllm/lib/python3.10/site-packages/ipykernel/kernelbase.py:1251\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pointllm/lib/python3.10/site-packages/ipykernel/kernelbase.py:1295\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(\"-\" * 80)\n",
    "    # Prompt for object_id\n",
    "    object_id = input(\"[INFO] Please enter the object_id or 'q' to quit: \")\n",
    "    \n",
    "    # Check if the user wants to quit\n",
    "    if object_id.lower() == 'q':\n",
    "        print(\"[INFO] Quitting...\")\n",
    "        break\n",
    "    else:\n",
    "        # print info\n",
    "        print(f\"[INFO] Chatting with object_id: {object_id}.\")\n",
    "    \n",
    "    # Update args with new object_id\n",
    "    args.object_id = object_id.strip()\n",
    "    \n",
    "    # Load the point cloud data\n",
    "    try:\n",
    "        id, point_clouds = load_point_cloud(args)\n",
    "        print(id)\n",
    "    except Exception as e:\n",
    "        # print(f\"[ERROR] {e}\")\n",
    "        # continue\n",
    "        point_clouds = load_my_own_point_cloud(object_id)\n",
    "        \n",
    "    point_clouds = point_clouds.cuda().to(torch.float16)\n",
    "    print(point_clouds.shape)\n",
    "\n",
    "    # Reset the conversation template\n",
    "    conv.reset()\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Start a loop for multiple rounds of dialogue\n",
    "    for i in range(100):\n",
    "        # This if-else block ensures the initial question from the user is included in the conversation\n",
    "        qs = input(conv.roles[0] + ': ')\n",
    "        if qs == 'exit':\n",
    "            break\n",
    "        \n",
    "        if i == 0:\n",
    "            if mm_use_point_start_end:\n",
    "                qs = default_point_start_token + default_point_patch_token * point_token_len + default_point_end_token + '\\n' + qs\n",
    "            else:\n",
    "                qs = default_point_patch_token * point_token_len + '\\n' + qs\n",
    "\n",
    "        # Append the new message to the conversation history\n",
    "        conv.append_message(conv.roles[0], qs)\n",
    "        conv.append_message(conv.roles[1], None)\n",
    "        prompt = conv.get_prompt()\n",
    "        inputs = tokenizer([prompt])\n",
    "\n",
    "        input_ids = torch.as_tensor(inputs.input_ids).cuda()\n",
    "\n",
    "        stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n",
    "        stop_str = keywords[0]\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            output_ids = model.generate(\n",
    "                input_ids,\n",
    "                point_clouds=point_clouds,\n",
    "                do_sample=True,\n",
    "                temperature=1.0,\n",
    "                top_k=50,\n",
    "                max_length=2048,\n",
    "                top_p=0.95,\n",
    "                stopping_criteria=[stopping_criteria])\n",
    "\n",
    "        input_token_len = input_ids.shape[1]\n",
    "        n_diff_input_output = (input_ids != output_ids[:, :input_token_len]).sum().item()\n",
    "        if n_diff_input_output > 0:\n",
    "            print(f'[Warning] {n_diff_input_output} output_ids are not the same as the input_ids')\n",
    "        outputs = tokenizer.batch_decode(output_ids[:, input_token_len:], skip_special_tokens=True)[0]\n",
    "        outputs = outputs.strip()\n",
    "        if outputs.endswith(stop_str):\n",
    "            outputs = outputs[:-len(stop_str)]\n",
    "        outputs = outputs.strip()\n",
    "\n",
    "        # Append the model's response to the conversation history\n",
    "        conv.pop_last_none_message()\n",
    "        conv.append_message(conv.roles[1], outputs)\n",
    "        print(f'{conv.roles[1]}: {outputs}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "018d3fd9-ae1e-4d8e-86d3-459fd39be557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(model_path='RunsenXu/PointLLM_7B_v1.1', data_path='/data2/llf/objaverse/8192_npy', torch_dtype='float32', object_id='/data2/llf/fss_data/ScanNet/scenes/data/scene0011_00.npy')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "199dcf13-27de-42ed-be67-431dfd151fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661575"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"/data2/llf/objaverse/8192_npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91997973-f777-407c-ae91-65c3484bd1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 513, 1152])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.point_backbone(torch.rand(1,200000,6).cuda().to(torch.float16)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe530d13-b750-4df1-8da4-a65b794398cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.point_backbone.num_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac1be8f6-544b-4914-b4c3-1f4ea30e893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_token_len = point_backbone_config['point_token_len']\n",
    "default_point_patch_token = point_backbone_config['default_point_patch_token']\n",
    "default_point_start_token = point_backbone_config['default_point_start_token']\n",
    "default_point_end_token = point_backbone_config['default_point_end_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc4221b-0fc3-4177-ab76-96a603b10dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<point_patch>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_point_patch_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "539c5455-adbb-4654-8bfa-382d3affb77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<point_start>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_point_start_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e12a067-5e97-4837-9caa-df650de06082",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mvocab_size\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcfe67e-4e1b-4180-b69a-7ca1f8c93038",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens(\"[SEG]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a9c1a-c4c7-49d6-9ff1-3ddab983e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26ec14e0-0633-4211-b858-48350f8f2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_token_idx = tokenizer(\"[SEG]\", add_special_tokens=False).input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42b601ab-0d59-40ce-aa62-5f0aec398e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32003"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_token_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7546f1-13f9-49bc-abfc-4d15884ef58a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PointSegTransformer' from 'pointllm.model.pointbert' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpointllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpointbert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PointSegTransformer\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PointSegTransformer' from 'pointllm.model.pointbert' (unknown location)"
     ]
    }
   ],
   "source": [
    "from pointllm.model.pointbert import PointSegTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d380262-89b1-4322-b50f-491cd38e1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input= torch.Tensor(1,8192,6).to(torch.float16).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa25e40d-4183-4074-85c7-f8e6f7b28f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.model.point_backbone(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4e0914c-d862-47c9-97a7-ad082c5c7b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 513, 1152])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b387d-cdbf-420e-900b-9415098be2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
