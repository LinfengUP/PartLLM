{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d296386e-a0e0-4f96-8d0a-a77c422c7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seg_xcoders import *\n",
    "import argparse\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "from pointllm.conversation import conv_templates, SeparatorStyle\n",
    "from pointllm.utils import disable_torch_init\n",
    "from pointllm.model import *\n",
    "from pointllm.model.utils import KeywordsStoppingCriteria\n",
    "\n",
    "from pointllm.data import load_ulip2_objaverse_point_cloud\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3232ae96-f1b4-492f-aa66-ef36c04503aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(args):\n",
    "    # Model\n",
    "    disable_torch_init()\n",
    "\n",
    "    model_path = args.model_path \n",
    "    print(f'[INFO] Model name: {model_path}')\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = PointLLMLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=False, use_cache=True, torch_dtype=torch.float16).cuda()\n",
    "                                                     # args.torch_dtype).cuda()\n",
    "    model.initialize_tokenizer_point_backbone_config_wo_embedding(tokenizer)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    mm_use_point_start_end = getattr(model.config, \"mm_use_point_start_end\", False)\n",
    "    # Add special tokens ind to model.point_config\n",
    "    point_backbone_config = model.get_model().point_backbone_config\n",
    "    \n",
    "    if mm_use_point_start_end:\n",
    "        if \"v1\" in model_path.lower():\n",
    "            conv_mode = \"vicuna_v1_1\"\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        conv = conv_templates[conv_mode].copy()\n",
    "\n",
    "    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "    keywords = [stop_str]\n",
    "    \n",
    "    return model, tokenizer, point_backbone_config, keywords, mm_use_point_start_end, conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0334c732-5ec1-45c4-99b0-b34f8177c525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model name: RunsenXu/PointLLM_7B_v1.1\n",
      "Loading PointBERT config from /home/linfeng/PointLLM/pointllm/model/pointbert/PointTransformer_base_8192point.yaml.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc296e8d7fc044b1bd4fd18329ae94b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model-path\", type=str, \\\n",
    "default=\"RunsenXu/PointLLM_7B_v1.1\")\n",
    "\n",
    "parser.add_argument(\"--data-path\", type=str, default=\"/data2/llf/objaverse/8192_npy\")\n",
    "parser.add_argument(\"--torch-dtype\", type=str, default=\"float32\", choices=[\"float32\", \"float16\", \"bfloat16\"])\n",
    "args = parser.parse_args(args=[])\n",
    "    # '--torch-dtype','float32'])\n",
    "model, tokenizer, point_backbone_config, keywords, mm_use_point_start_end, conv = init_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24a6c8ea-b2c4-4010-a1e1-2252268be927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'point_cloud_dim': 6,\n",
       " 'backbone_output_dim': 1152,\n",
       " 'project_output_dim': 4096,\n",
       " 'point_token_len': 513,\n",
       " 'mm_use_point_start_end': True,\n",
       " 'projection_hidden_layer': 0,\n",
       " 'use_max_pool': False,\n",
       " 'default_point_patch_token': '<point_patch>',\n",
       " 'point_patch_token': 32000,\n",
       " 'default_point_start_token': '<point_start>',\n",
       " 'default_point_end_token': '<point_end>',\n",
       " 'point_start_token': 32001,\n",
       " 'point_end_token': 32002}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_backbone_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf8fc5-4377-44ad-aee9-9b2b208fdeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
