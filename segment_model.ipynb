{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a6b33f-05f3-4886-9a36-9a9e334415aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "from pointllm.conversation import conv_templates, SeparatorStyle\n",
    "from pointllm.utils import disable_torch_init\n",
    "from pointllm.model import *\n",
    "from pointllm.model.utils import KeywordsStoppingCriteria\n",
    "\n",
    "from pointllm.data import load_ulip2_objaverse_point_cloud\n",
    "import copy\n",
    "import os\n",
    "from pointllm.model.pointbert.seg_xcoders import *\n",
    "from easydict import EasyDict\n",
    "import yaml\n",
    "import torch.nn as nn\n",
    "from pointllm.model.pointbert.pointnet2_utils import PointNetFeaturePropagation\n",
    "from pointnet2_ops import pointnet2_utils\n",
    "from pointllm.model.pointbert.transformer  import TwoWayTransformer\n",
    "from torch.nn import functional as F\n",
    "from pointllm.model.pointbert.point_segmentor import PointSegTransformer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9102a112-0785-496d-a7bd-cc05e914ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfg_from_yaml_file(cfg_file):\n",
    "    config = EasyDict()\n",
    "    with open(cfg_file, 'r') as f:\n",
    "        new_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    merge_new_config(config=config, new_config=new_config)\n",
    "    return config\n",
    "def merge_new_config(config, new_config):\n",
    "    for key, val in new_config.items():\n",
    "        if not isinstance(val, dict):\n",
    "            if key == '_base_':\n",
    "                with open(new_config['_base_'], 'r') as f:\n",
    "                    try:\n",
    "                        val = yaml.load(f, Loader=yaml.FullLoader)\n",
    "                    except:\n",
    "                        val = yaml.load(f)\n",
    "                config[key] = EasyDict()\n",
    "                merge_new_config(config[key], val)\n",
    "            else:\n",
    "                config[key] = val\n",
    "                continue\n",
    "        if key not in config:\n",
    "            config[key] = EasyDict()\n",
    "        merge_new_config(config[key], val)\n",
    "    return config\n",
    "def fps(data, number):\n",
    "    '''\n",
    "        data B N 3\n",
    "        number int\n",
    "    '''\n",
    "    fps_idx = pointnet2_utils.furthest_point_sample(data, number) \n",
    "    fps_data = pointnet2_utils.gather_operation(data.transpose(1, 2).contiguous(), fps_idx).transpose(1,2).contiguous()\n",
    "    return fps_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "004090f9-e73e-4485-a85a-3893c3954b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_bert_config_name = \"./pointllm/model/pointbert/PointTransformer_base_8192point.yaml\"\n",
    "point_bert_config = cfg_from_yaml_file(point_bert_config_name)\n",
    "point_bert_config.model.point_dims = 6\n",
    "use_max_pool = getattr(point_bert_config.model, \"use_max_pool\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b378377e-6f3e-40f3-9c61-dd0fec10e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointllm.model.pointbert.part_prompt_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e805c722-d009-4c12-930a-583192c78c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PartPromptDataset(point_bert_config)\n",
    "dataloader= DataLoader(dataset,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a606ee-71d0-4636-8514-ecde1a5d8e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataloader:\n",
    "    data = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a40646f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8192, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c4171-c477-40c1-be38-6e8602ae8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/data1/linfeng/PartLLM/experiment-5/model_34000.pth\", map_location=lambda storage, loc: storage.cuda())\n",
    "segmentor = PointSegTransformer(point_bert_config,use_max_pool).cuda()\n",
    "# segmentor.prompt_encoder.load_state_dict(checkpoint[\"prompt_encoder\"])\n",
    "# segmentor.mask_decoder.load_state_dict(checkpoint[\"mask_decoder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224baab-6612-4d53-9939-347098e0b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "point,text_embedding, label,_ = data\n",
    "point = point.cuda()\n",
    "text_embedding = text_embedding.cuda()\n",
    "mask,iou = segmentor(point,text_embedding)\n",
    "mask = mask>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa39f3-18e9-4b7b-a12b-1ed071e57689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8192])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a955a4a-c78c-499a-a189-1d50a0fdc56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************************************************************\n",
      "1) Start local server:\n",
      "    cd /home/linfeng/PartLLM/parnet_vis/example_point_clouds; python -m http.server 6008\n",
      "2) Open in browser:\n",
      "    http://0.0.0.0:6008\n",
      "************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import pyviz3d.visualizer as viz\n",
    "ind = 5\n",
    "v = viz.Visualizer()\n",
    "points = point[ind].cpu().numpy()\n",
    "color1 = np.zeros((points.shape[0],3))\n",
    "color1[label[ind]==1] = [255.0,0,0]\n",
    "v.add_points(\"label\", points[:,:3], color1, point_size=10)\n",
    "color2 = np.zeros((points.shape[0],3))\n",
    "color2[mask[ind].cpu()==True] = [0,255,0]\n",
    "v.add_points(\"predict\", points[:,:3], color2, point_size=10)\n",
    "v.save('./parnet_vis/example_point_clouds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f546df5-7676-4600-8f2e-78b6d1ab5398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e090c-785e-4c30-b640-0a2097f1b9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30415d60-17f9-49f0-82ef-6cad0407b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "point,text_embedding,label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b9fde-4052-4247-923c-3cc0ad8c0c83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'point' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpoint\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'point' is not defined"
     ]
    }
   ],
   "source": [
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a77ae8-7e6e-4e20-9737-40e2b20ed469",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentor = PointSegTransformer(point_bert_config,use_max_pool).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678121cb-1a72-4e8a-807c-07bb839a7a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks,iou_pred = segmentor(data[0].cuda(),data[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e90a819-34b4-4f3e-a33e-4e7588c26115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8192])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc77f794-772e-4362-b5d7-84c8d2204575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca2b01-79ea-4546-8ff5-09a1bca1f932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8192])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b49e4-2cef-4ed9-b3ef-e93c62ff7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_backbone = PointEncoder(point_bert_config.model, use_max_pool=use_max_pool).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecb411-f525-4da8-b898-1a2220481dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.Tensor(3,8192,6).cuda()\n",
    "# for i in range(input.shape[0]):\n",
    "#     input[i] = pc_norm(input[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93468f-79c0-4c9b-be83-c8635fdef274",
   "metadata": {},
   "outputs": [],
   "source": [
    "ouput = point_backbone(input)[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a900e-a1c7-4f17-a99f-8d790925b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_encoder = PromptEncoder(point_bert_config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46aaaf-96bf-411d-b7ff-596bf75ffa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = torch.Tensor(3,512).cuda().unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8262f-c45c-47e5-ad13-f3ed3e42c75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1eb95-cec7-462e-b790-ffb9ed382d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = prompt_encoder(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3cf30-c948-4807-87ce-814fc3438b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_backbone.pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e10851-a906-46ff-bb43-8da74efb566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_decoder = MaskDecoder(point_bert_config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3cdc7d-fcc4-4861-8a6d-fbd5e705c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ouput.shape[0]):\n",
    "    x = mask_decoder(point_backbone.pts[i:i+1],input[i:i+1,:,:3],ouput[i:i+1],out[i:i+1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0468190-e941-4d6e-8fcf-4a43a3456435",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m prompts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m512\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      4\u001b[0m point_embedding \u001b[38;5;241m=\u001b[39m point_backbone(pts)[:,\u001b[38;5;241m1\u001b[39m:,:]\n\u001b[0;32m----> 5\u001b[0m prompt_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_encoder\u001b[49m(prompts)\n\u001b[1;32m      6\u001b[0m masks,iou_pred \u001b[38;5;241m=\u001b[39m mask_decoder(point_backbone\u001b[38;5;241m.\u001b[39mpts,pts[:,:,:\u001b[38;5;241m3\u001b[39m],point_embedding,prompt_embedding)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "pts = torch.Tensor(3,8192,6).cuda()\n",
    "prompts = torch.Tensor(3,1,512).cuda()\n",
    "\n",
    "point_embedding = point_backbone(pts)[:,1:,:]\n",
    "prompt_embedding = prompt_encoder(prompts)\n",
    "masks,iou_pred = mask_decoder(point_backbone.pts,pts[:,:,:3],point_embedding,prompt_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cd9bd-a724-4012-810b-444250995650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d13ea6-9f65-4dc5-b50f-9e749299ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        output_dim: int,\n",
    "        num_layers: int,\n",
    "        sigmoid_output: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        h = [hidden_dim] * (num_layers - 1)\n",
    "        self.layers = nn.ModuleList(\n",
    "            nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim])\n",
    "        )\n",
    "        self.sigmoid_output = sigmoid_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = F.relu(layer(x)) if i < self.num_layers - 1 else layer(x)\n",
    "        if self.sigmoid_output:\n",
    "            x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13958749-21c4-4a12-a246-f39aee2fb8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class PointEncoder(nn.Module):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = torch.load(config.point_encoder_path)\n",
    "\n",
    "    def forward(input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96ca19-6e72-4e65-84de-4003d8229e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f22aecf-5e8a-4364-b763-18c8496dfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptEncoder(nn.Module):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = config.out_dim\n",
    "\n",
    "        self.no_mask_embed = nn.Embedding(1, self.embed_dim)\n",
    "\n",
    "    def _get_batch_size(self,prompt):\n",
    "        if prompt is not None:\n",
    "            return prompt.shape[0]\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def forward(self, prompt, **kwargs):\n",
    "        bs = self._get_batch_size(prompt)\n",
    "        sparse_embeddings = torch.empty((bs,0,self.embed_dim), device = self.no_mask_embed.weight.device)\n",
    "\n",
    "        if prompt is not None:\n",
    "            sparse_embeddings = torch.cat([sparse_embeddings, prompt], dim = 1)\n",
    "\n",
    "        return sparse_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08532fd0-70ca-4cb3-a4ac-a04b374d2058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff19216-3856-454f-90c7-c1e503fa8846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(1, None, None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice(1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e0181-f673-405e-be66-8a47ff1fcf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(0, 1, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad2ba5-8402-4306-bae8-968ad62383bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.random.randn(2,4,10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c6ad1-905a-4624-8846-973f0d68af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(args):\n",
    "    # Model\n",
    "    disable_torch_init()\n",
    "\n",
    "    model_path = args.model_path \n",
    "    print(f'[INFO] Model name: {model_path}')\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = PointLLMLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=False, use_cache=True, torch_dtype=torch.float16).cuda()\n",
    "                                                     # args.torch_dtype).cuda()\n",
    "    model.initialize_tokenizer_point_backbone_config_wo_embedding(tokenizer)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    mm_use_point_start_end = getattr(model.config, \"mm_use_point_start_end\", False)\n",
    "    # Add special tokens ind to model.point_config\n",
    "    point_backbone_config = model.get_model().point_backbone_config\n",
    "    \n",
    "    if mm_use_point_start_end:\n",
    "        if \"v1\" in model_path.lower():\n",
    "            conv_mode = \"vicuna_v1_1\"\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        conv = conv_templates[conv_mode].copy()\n",
    "\n",
    "    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "    keywords = [stop_str]\n",
    "    \n",
    "    return model, tokenizer, point_backbone_config, keywords, mm_use_point_start_end, conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c55fc1-a4fc-4277-93ca-d2389ab4e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def pc_norm(pc):\n",
    "    \"\"\" pc: NxC, return NxC \"\"\"\n",
    "    xyz = pc[:, :3]\n",
    "    other_feature = pc[:, 3:]\n",
    "\n",
    "    centroid = np.mean(xyz, axis=0)\n",
    "    xyz = xyz - centroid\n",
    "    m = np.max(np.sqrt(np.sum(xyz ** 2, axis=1)))\n",
    "    xyz = xyz / m\n",
    "\n",
    "    pc = np.concatenate((xyz, other_feature), axis=1)\n",
    "    return pc\n",
    "def load_ulip2_objaverse_point_cloud(data_path, object_id, pointnum=8192, use_color=False):\n",
    "\n",
    "    if not use_color:\n",
    "        filename = f\"{object_id}/{object_id}_{pointnum}.npz\"\n",
    "        point_cloud = np.load(os.path.join(data_path, filename))['arr_0'] # * pointnum, 3 array\n",
    "    else:\n",
    "        filename = f\"{object_id}_{pointnum}.npy\"\n",
    "        point_cloud = np.load(os.path.join(data_path, filename))\n",
    "\n",
    "    # * normalize\n",
    "    point_cloud = pc_norm(point_cloud)\n",
    "\n",
    "    return point_cloud\n",
    "\n",
    "def load_my_own_point_cloud(object_id):\n",
    "    # /data2/llf/fss_data/ScanNet/scenes/data/scene0000_00.npy\n",
    "    point_cloud = np.load(object_id)\n",
    "    point_cloud = point_cloud[:,:6]\n",
    "    point_cloud[:,3:] = point_cloud[:,3:]/255\n",
    "\n",
    "    point_cloud = pc_norm(point_cloud)\n",
    "\n",
    "    return torch.from_numpy(point_cloud).unsqueeze_(0).to(torch.float32)\n",
    "    \n",
    "\n",
    "def load_point_cloud(args):\n",
    "    object_id = args.object_id\n",
    "    print(f\"[INFO] Loading point clouds using object_id: {object_id}\")\n",
    "    point_cloud = load_ulip2_objaverse_point_cloud(args.data_path, object_id, pointnum=8192, use_color=True)\n",
    "    \n",
    "    return object_id, torch.from_numpy(point_cloud).unsqueeze_(0).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60525035-3ea4-4676-9c11-a8ad10418400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model-path\", type=str, \\\n",
    "default=\"RunsenXu/PointLLM_7B_v1.1\")\n",
    "\n",
    "parser.add_argument(\"--data-path\", type=str, default=\"/data2/llf/objaverse/8192_npy\")\n",
    "parser.add_argument(\"--torch-dtype\", type=str, default=\"float32\", choices=[\"float32\", \"float16\", \"bfloat16\"])\n",
    "args = parser.parse_args(args=[])\n",
    "    # '--torch-dtype','float32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5b3dc-f780-4bd3-b5a1-928449417c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model name: RunsenXu/PointLLM_7B_v1.1\n",
      "Loading PointBERT config from /home/linfeng/PartLLM/pointllm/model/pointbert/PointTransformer_base_8192point.yaml.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e8af772a824edda4d89d54930b11ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer, point_backbone_config, keywords, mm_use_point_start_end, conv = init_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eeae81-8aea-4199-b3a5-3df2749f4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_encoder =copy.deepcopy(model.model.point_backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293c2b7-3e84-467e-87e3-ae418f9262b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(point_encoder,\"point_encoder_7B.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389ffa4-3f60-4260-988c-6963921fcdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 3573, 310, 11774], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"body of chair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54320bb-0217-4b96-bc7e-43294ab6afd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizer(name_or_path='RunsenXu/PointLLM_7B_v1.1', vocab_size=32000, model_max_length=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<unk>'})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b06f8-38e5-4277-82c1-cc3079d988f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_embed = copy.deepcopy(model.model.embed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c8a37-cde1-4d6f-bcb0-f8c260398459",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(voc_embed,\"voc_embed_7B.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0909853-d594-45af-a640-4ed56d046306",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvoc_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody of chair\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pointllm/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pointllm/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pointllm/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "voc_embed(tokenizer(\"body of chair\")['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927b2f0-446d-4fd3-9cd2-aaafdc3d050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a848c817-7483-48b8-adaf-41d0f65ec705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67edeb83275b4af596281c0b8262f1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabd6380cf724ddc8bd026a2ec014944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d57347f-7945-49b2-99aa-3b29783a92a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b0c80522434226870727f6e7992894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cd3fb1734949b8832e389e3cd0d17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/568 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375c1025cd0b4b65a326593ff67ee3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee67afdb37849a69825bbc335720630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a2a5f531b64ceca9ba5b68b16e2231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8143b55b854e49b653cec7029c60ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55600a71-3741-4f77-87a4-a4a1f1f21d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d05282-b5ca-4702-8b4b-1c7898c010c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[49406,   320,  1125,   539,   320,  2368, 49407],\n",
       "        [49406,   320,  1125,   539,   320,  1929, 49407]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57833f6-5e80-431b-8520-ca630a534b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = model.get_text_features(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb1a05f-6eec-4ebd-add0-a7ab3ad5aaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487a81f-b189-4b76-a382-45339bf30662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./parnet_vis/meta_class.json', 'r') as fcc_file:\n",
    "    meta_class = json.load(fcc_file)\n",
    "meta_class = [\" \".join(x.split(\"_\")) for x in meta_class]\n",
    "inputs = processor(text=meta_class, return_tensors=\"pt\", padding=True)\n",
    "text_features = model.get_text_features(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c0ecb-0857-42f3-8096-74068d185ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(text_features,\"./text_features.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb9eba-795b-42dc-882e-86d50b7393c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8192, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1,8192,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39636b-beda-4d41-8df6-12df45afa5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_encoder = point_encoder.to(torch.float32)\n",
    "point_feature = point_encoder(torch.rand(1,8192,6).to(torch.float32).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c64e1d-87fe-426c-a544-b46ceb9bcbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 513, 1152])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7df33-07c5-4a05-911e-26720d477823",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = torch.nn.LayerNorm(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f77280-1e15-458a-8d1f-e3693d715c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a493c97-43f7-4a80-812f-8259ce297f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = torch.nn.BatchNorm2d(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78395bf-b03f-4dea-b7b3-c6fddc8587f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa3917-51e0-41a8-b2b2-80ee03492eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.normal(0,1,size=(8,100)).sigmoid()\n",
    "b=(torch.normal(0,1,size=(8,100))>0).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ece8de-3307-452f-9e91-446c8c65e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = a\n",
    "targets = b\n",
    "scale = 1000\n",
    "eps = 1e-6\n",
    "numerator = 2 * (inputs / scale * targets).sum(-1)\n",
    "denominator = (inputs / scale).sum(-1) + (targets / scale).sum(-1)\n",
    "loss = 1 - (numerator + eps) / (denominator + eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da030d-40e4-4c33-a40c-b5b192d1bc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5685, 0.5047, 0.4492, 0.4678, 0.4971, 0.4818, 0.5235, 0.5119])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe036e8-17c9-4feb-9bac-084f7fdf1c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 25, 30, 28, 24, 28, 27, 20])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= (a>0.5).long()\n",
    "(c*targets).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ff4db-907d-4235-a499-1742e5dc2fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46, 51, 52, 48, 44, 52, 59, 40])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d6808-9696-42d5-a7c0-fddc482cc197",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (c*targets).sum(-1)/torch.sum(c,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae49fa-9e6a-4445-9a39-10d84082f995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672804d8-5bed-4b36-8736-3bc804fe163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = torch.load(\"/data2/llf/partnet/text_embeddings.pth\").detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78118bad-7ca5-46b1-9794-54e324a25f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(text,\"/data2/llf/partnet/text_embeddings.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a1af0-240e-4dd8-bdfa-3c0d0a9d98e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
